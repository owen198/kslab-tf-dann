{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Lambda\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.engine.training import _make_batches as make_batches\n",
    "# from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "from flipGradientTF import GradientReversal\n",
    "from loader import load_3a_data, load_chk_data\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "nb_epoch = 30\n",
    "_TRAIN = K.variable(1, dtype='uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from college and senior high data sets\n",
    "### Source Data: College, a.k.a., 3a\n",
    "### Target Data: Senior high, a.k.a., chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of each datasets: source:  295 target:  295\n"
     ]
    }
   ],
   "source": [
    "SCALE = True\n",
    "OVERSAMPLING = False\n",
    "\n",
    "xs_train_1a, ys_train_1a = load_3a_data('ncu_data_week_1-6(1a).csv', oversampling=OVERSAMPLING, scale=SCALE)\n",
    "xs_train_2a, ys_train_2a = load_3a_data('ncu_data_week_1-12(2a).csv', oversampling=OVERSAMPLING, scale=SCALE)\n",
    "xs_train_3a, ys_train_3a = load_3a_data('ncu_data_week_1-18(3a).csv', oversampling=OVERSAMPLING, scale=SCALE)\n",
    "xs_train_2d, ys_train_2d = load_3a_data('ncu_data_week_7-12(2d).csv', oversampling=OVERSAMPLING, scale=SCALE)\n",
    "xs_train_3d, ys_train_3d = load_3a_data('ncu_data_week_13-18(3d).csv', oversampling=OVERSAMPLING, scale=SCALE)\n",
    "\n",
    "xs_train = np.concatenate((xs_train_1a, xs_train_2a, xs_train_3a, xs_train_2d, xs_train_3d), axis=0)\n",
    "ys_train_3a = np.concatenate((ys_train_1a, ys_train_2a, ys_train_3a, ys_train_2d, ys_train_3d), axis=0)\n",
    "ys_train = to_categorical(ys_train_3a)\n",
    "\n",
    "xt_train_chka, yt_train_chka = load_chk_data('ncu_data_week_chka_1-6.csv', oversampling=OVERSAMPLING, scale=SCALE)\n",
    "xt_train_chkb, yt_train_chkb = load_chk_data('ncu_data_week_chkb_1-6.csv', oversampling=OVERSAMPLING, scale=SCALE)\n",
    "xt_train = np.concatenate((xt_train_chka, xt_train_chkb),axis=0)\n",
    "yt_train_chk = np.concatenate((yt_train_chka, yt_train_chkb),axis=0)\n",
    "\n",
    "xt_train = xt_train[range(0, len(ys_train_3a))]\n",
    "yt_train = to_categorical(yt_train_chk[range(0, len(ys_train_3a))])\n",
    "\n",
    "print(\"length of each datasets:\", \"source: \", len(ys_train), \"target: \", len(yt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create domain classification labels\n",
    "domain_labels = np.vstack([np.tile([0, 1], [int(batch_size / 2), 1]),\n",
    "                           np.tile([1., 0.], [int(batch_size / 2), 1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate models, batches, and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(batches, id_array, data, labels):\n",
    "    for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "        batch_ids = id_array[batch_start:batch_end]\n",
    "        if labels is not None:\n",
    "            yield data[batch_ids], labels[batch_ids]\n",
    "        else:\n",
    "            yield data[batch_ids]\n",
    "        np.random.shuffle(id_array)\n",
    "        \n",
    "def imshow_grid(images, shape=[2, 8]):\n",
    "    \"\"\"Plot images in a grid of a given shape.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n",
    "\n",
    "    size = shape[0] * shape[1]\n",
    "    for i in range(size):\n",
    "        grid[i].axis('off')\n",
    "        # The AxesGrid object work as a list of axes.\n",
    "        grid[i].imshow(np.swapaxes(np.swapaxes(images[i], 0, 2), 0, 1))\n",
    "        \n",
    "def plot_embedding(X, y, d, title=None):\n",
    "    \"\"\"Plot an embedding X with the class label y colored by the domain d.\"\"\"\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Plot colors numbers\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        # plot colored number\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.bwr(d[i] / 1.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANNBuilder(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.net = None\n",
    "        self.domain_invariant_features = None\n",
    "        self.grl = None\n",
    "        self.opt = SGD()\n",
    "\n",
    "    def _build_feature_extractor(self, model_input):\n",
    "        '''Build segment of net for feature extraction.'''\n",
    "        net = Dense(units=19, activation='relu', input_dim=19)(model_input)\n",
    "        self.domain_invariant_features = net\n",
    "        return net\n",
    "\n",
    "    def _build_classifier(self, model_input):\n",
    "        net = Dense(38, activation='relu')(model_input)\n",
    "        net = Dropout(0.1)(net)\n",
    "        net = Dense(units=2, activation='softmax', name='classifier_output')(model_input)\n",
    "        return net\n",
    "\n",
    "    def build_source_model(self, main_input, plot_model=False):\n",
    "        net = self._build_feature_extractor(main_input)\n",
    "        net = self._build_classifier(net)\n",
    "        model = Model(inputs=main_input, outputs=net)\n",
    "        model.compile(loss={'classifier_output': 'categorical_crossentropy'},\n",
    "                      optimizer=self.opt, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def build_dann_model(self, main_input, plot_model=False):\n",
    "        net = self._build_feature_extractor(main_input)\n",
    "        self.grl = GradientReversal(1.0)\n",
    "        branch = self.grl(net)\n",
    "        branch = Dense(128, activation='relu')(branch)\n",
    "        branch = Dropout(0.1)(branch)\n",
    "        branch = Dense(2, activation='relu', name='domain_output')(branch)\n",
    "\n",
    "        # When building DANN model, route first half of batch (source examples)\n",
    "        # to domain classifier, and route full batch (half source, half target)\n",
    "        # to the domain classifier.\n",
    "        # 先前面一半的 data 拿去 domain classifier\n",
    "#         net = Lambda(lambda x: K.switch(K.learning_phase(),\n",
    "#                      x[:int(batch_size / 2), :], x),\n",
    "#                      output_shape=lambda x: ((batch_size / 2,) +\n",
    "#                      x[1:]) if _TRAIN else x[0:])(net)\n",
    "\n",
    "        net = self._build_classifier(net)\n",
    "        #model for source data\n",
    "        model_src = Model(inputs=main_input, outputs=[branch, net])\n",
    "        #model for target data\n",
    "        model_tgt = Model(inputs=main_input, outputs=[branch])\n",
    "\n",
    "        model_src.compile(loss={'classifier_output': 'categorical_crossentropy',\n",
    "                      'domain_output': 'categorical_crossentropy'},\n",
    "                      optimizer=self.opt, metrics=['accuracy'])\n",
    "\n",
    "        model_tgt.compile(loss={'domain_output': 'categorical_crossentropy'},\n",
    "                      optimizer=self.opt, metrics=['accuracy'] )\n",
    "#         model = Model(input=main_input, output=[branch, net])\n",
    "#         if plot_model:\n",
    "#             plot(model, show_shapes=True)\n",
    "#         model.compile(loss='categorical_crossentropy',\n",
    "#                       optimizer=self.opt, metrics=['accuracy'])\n",
    "        return (model_src, model_tgt)\n",
    "\n",
    "    def build_tsne_model(self, main_input):\n",
    "        '''Create model to output intermediate layer\n",
    "        activations to visualize domain invariant features'''\n",
    "        tsne_model = Model(inputs=main_input,\n",
    "                           outputs=self.domain_invariant_features)\n",
    "        return tsne_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(19,), name='main_input')\n",
    "builder = DANNBuilder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Source (3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 218us/step\n",
      "Source(3a) Only Accuracy:  0.7796610175553015\n",
      "295/295 [==============================] - 0s 54us/step\n",
      "Source(3a) to Target Accuracy:  0.7016949154562869\n"
     ]
    }
   ],
   "source": [
    "src_model = builder.build_source_model(main_input)\n",
    "#print('Training source only model')\n",
    "src_model.fit(xs_train, ys_train, batch_size=batch_size, epochs=nb_epoch, verbose=0)\n",
    "\n",
    "plot_model(src_model, to_file='model.png')\n",
    "\n",
    "source_only_accuracy = src_model.evaluate(xs_train, ys_train)[1]\n",
    "print('Source(3a) Only Accuracy: ', source_only_accuracy)\n",
    "\n",
    "source_model_on_target_accuracy = src_model.evaluate(xt_train, yt_train)[1]\n",
    "print('Source(3a) to Target Accuracy: ', source_model_on_target_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Target (chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target(chk) only model\n",
      "295/295 [==============================] - 0s 233us/step\n",
      "Target(chk) Only Accuracy:  0.976271186440678\n",
      "295/295 [==============================] - 0s 49us/step\n",
      "Target(chk) to Source Accuracy:  0.46779661027051633\n"
     ]
    }
   ],
   "source": [
    "\n",
    "src_model = builder.build_source_model(main_input)\n",
    "print('Training target(chk) only model')\n",
    "src_model.fit(xt_train, yt_train, batch_size=batch_size, epochs=nb_epoch, verbose=0)\n",
    "\n",
    "target_only_accuracy = src_model.evaluate(xt_train, yt_train)[1]\n",
    "print('Target(chk) Only Accuracy: ', target_only_accuracy)\n",
    "\n",
    "target_model_on_source_accuracy = src_model.evaluate(xs_train, ys_train)[1]\n",
    "print('Target(chk) to Source Accuracy: ', target_model_on_source_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/.local/lib/python3.5/site-packages/keras/engine/topology.py:638: UserWarning: Class `flipGradientTF.GradientReversal` defines `get_output_shape_for` but does not override `compute_output_shape`. If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\n",
      "  output_shape = self.compute_output_shape(input_shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DANN model\n",
      "Epoch  0 <generator object batch_gen at 0x7f0ea0704fc0>\n",
      "Epoch  6 <generator object batch_gen at 0x7f0ea0704fc0>\n",
      "Epoch  12 <generator object batch_gen at 0x7f0ea0704fc0>\n",
      "Epoch  18 <generator object batch_gen at 0x7f0ea0704fc0>\n",
      "Epoch  24 <generator object batch_gen at 0x7f0ea0704fc0>\n"
     ]
    }
   ],
   "source": [
    "# Broken out training loop for a DANN model.\n",
    "source_index_arr = np.arange(xs_train.shape[0])\n",
    "target_index_arr = np.arange(xt_train.shape[0])\n",
    "\n",
    "#nb_epoch = nb_epoch * 10\n",
    "\n",
    "batches_per_epoch = len(xs_train) / batch_size\n",
    "num_steps = nb_epoch * batches_per_epoch\n",
    "\n",
    "# initialize DANN model\n",
    "#main_input = Input(shape=(19,), name='main_input')\n",
    "#builder = DANNBuilder()\n",
    "dann_src_model, dann_tgt_model = builder.build_dann_model(main_input)\n",
    "\n",
    "plot_model(dann_src_model, to_file='dann_src_model.png')\n",
    "\n",
    "j = 0\n",
    "\n",
    "print('Training DANN model')\n",
    "\n",
    "metric_src_epoch_list = []\n",
    "metric_tgt_epoch_list = []\n",
    "\n",
    "for i in range(nb_epoch):\n",
    "\n",
    "    source_batches = make_batches(xs_train.shape[0], int(batch_size / 2))\n",
    "    target_batches = make_batches(xt_train.shape[0], int(batch_size / 2))\n",
    "\n",
    "    source_gen = batch_gen(source_batches, source_index_arr, xs_train, ys_train)\n",
    "    target_gen = batch_gen(target_batches, target_index_arr, xt_train, None)\n",
    "\n",
    "    losses = list()\n",
    "    acc = list()\n",
    "\n",
    "    if i % (nb_epoch / 5) == 0:\n",
    "        #print 'loss: %f, domain accuracy: %f, class accuracy: %f' % (loss, da, pa)\n",
    "        print('Epoch ', i, source_gen)\n",
    "    \n",
    "    metric_src_batch_list = []\n",
    "    metric_tgt_batch_list = []\n",
    "\n",
    "    for (xs_batch, ys_batch) in source_gen:\n",
    "\n",
    "        # Update learning rate and gradient multiplier as described in the paper.\n",
    "        p = float(j) / num_steps\n",
    "        l = 2. / (1. + np.exp(-10. * p)) - 1\n",
    "        lr = 0.01 / (1. + 10 * p)**0.75\n",
    "        builder.grl.l = l\n",
    "        builder.opt.lr = lr\n",
    "\n",
    "        #print('xb.shape[0]', xb.shape[0])\n",
    "        if xs_batch.shape[0] != batch_size / 2:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            #print('try')\n",
    "            xt_batch = next(target_gen)\n",
    "        except:\n",
    "            # Regeneration\n",
    "            target_gen = batch_gen(target_batches, target_index_arr, xt_train, None)\n",
    "\n",
    "        metric_src = dann_src_model.train_on_batch({'main_input': xs_batch},\n",
    "                                            {'classifier_output': ys_batch,\n",
    "                                            'domain_output': domain_labels[:batch_size//2]},\n",
    "                                            )\n",
    "        \n",
    "        metric_src_batch_list.append(metric_src)\n",
    "        \n",
    "        metric_tgt = dann_tgt_model.train_on_batch({'main_input': xt_batch},\n",
    "                                            {'domain_output': domain_labels[batch_size//2:]},\n",
    "                                            )\n",
    "        \n",
    "        metric_tgt_batch_list.append(metric_tgt)\n",
    "        j += 1\n",
    "        \n",
    "    metric_src_mean = np.mean(np.asarray(metric_src_batch_list), axis=0)\n",
    "    metric_tgt_mean = np.mean(np.asarray(metric_tgt_batch_list), axis=0)\n",
    "\n",
    "    metric_src_epoch_list.append(metric_src_mean)\n",
    "    metric_tgt_epoch_list.append(metric_tgt_mean)\n",
    "    #print(\"tgt_metric\", metric_tgt_mean,\"\\nsrc_metric\", metric_src_mean)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANN model is training by xs_train, ys_train, xt_train\n",
      "Evaluating source samples on DANN model\n",
      "DANN to Source Accuracy(chk):  0.3559322033898305\n",
      "Evaluating target samples on DANN model\n",
      "DANN to Target Accuracy(3a):  0.8169491525423729\n",
      "Evaluating domain classification\n",
      "Domain Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "print('DANN model is training by xs_train, ys_train, xt_train')\n",
    "\n",
    "print('Evaluating source samples on DANN model')\n",
    "dann_src_model_out = dann_src_model.predict_on_batch(xs_train)\n",
    "dann_src_model_classifier_out = np.argmax(dann_src_model_out[1], axis=1)\n",
    "dann_src_model_classifier_out_actual = np.argmax(ys_train, axis=1)\n",
    "dann_to_source_acc = float(np.sum((dann_src_model_classifier_out == dann_src_model_classifier_out_actual))) / float(len(dann_src_model_classifier_out))\n",
    "print('DANN to Source Accuracy(chk): ', dann_to_source_acc)\n",
    "\n",
    "print('Evaluating target samples on DANN model')\n",
    "dann_tgt_model_out = dann_src_model.predict_on_batch(xt_train)\n",
    "dann_tgt_model_classifier_out = np.argmax(dann_tgt_model_out[1], axis=1)\n",
    "dann_tgt_model_classifier_out_actual = np.argmax(yt_train, axis=1)\n",
    "dann_to_target_acc = float(np.sum((dann_tgt_model_classifier_out == dann_tgt_model_classifier_out_actual))) / float(len(dann_tgt_model_classifier_out))\n",
    "print('DANN to Target Accuracy(3a): ', dann_to_target_acc)\n",
    "\n",
    "print('Evaluating domain classification')\n",
    "dann_tgt_model_out = dann_tgt_model.predict_on_batch(np.concatenate((xs_train, xt_train), axis=0))\n",
    "dann_tgt_model_domain_out = np.argmax(dann_tgt_model_out, axis=1)\n",
    "dann_tgt_model_domain_out_actual = np.argmax(np.vstack([\n",
    "    np.tile([0, 1], [len(xs_train), 1]),\n",
    "    np.tile([1., 0.], [len(xt_train), 1])\n",
    "]), axis=1)\n",
    "domain_classification_acc = float(np.sum((dann_tgt_model_domain_out == dann_tgt_model_domain_out_actual))) / float(len(dann_tgt_model_domain_out))\n",
    "print('Domain Accuracy: ', domain_classification_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source only accuracy: 0.7796610175553015\n",
      "dann on target: 0.8169491525423729\n",
      "dann on target accuracy should between 0.7016949154562869 and 0.976271186440678\n"
     ]
    }
   ],
   "source": [
    "print (\"source only accuracy:\", source_only_accuracy)\n",
    "print (\"dann on target:\", dann_to_target_acc)\n",
    "print (\"dann on target accuracy should between\", source_model_on_target_accuracy, \"and\", target_only_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-302d5b5481da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msrc_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_vis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_test_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msrc_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_tsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m plot_embedding(tsne, combined_test_labels.argmax(1),\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \"\"\"\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             X = check_array(X, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 660\u001b[0;31m                             dtype=[np.float32, np.float64])\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'barnes_hut'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             raise ValueError(\"'n_components' should be inferior to 4 for the \"\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# imshow_grid(x_train)\n",
    "# imshow_grid(xt_train)\n",
    "src_vis = builder.build_tsne_model(main_input)\n",
    "dann_vis = builder.build_tsne_model(main_input)\n",
    "# Created mixed dataset for TSNE visualization\n",
    "# num_test = 500\n",
    "combined_test_imgs = np.vstack([xs_train[:], xt_train[:]])\n",
    "combined_test_labels = np.vstack([ys_train[:], yt_train[:]])\n",
    "combined_test_domain = np.vstack([np.tile([1., 0.], [len(xs_train), 1]),\n",
    "                                 np.tile([0., 1.], [len(xt_train), 1])])\n",
    "\n",
    "src_embedding = src_vis.predict([combined_test_imgs])\n",
    "src_tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=300)\n",
    "tsne = src_tsne.fit_transform(src_embedding)\n",
    "\n",
    "plot_embedding(tsne, combined_test_labels.argmax(1),\n",
    "               combined_test_domain.argmax(1), 'Source only')\n",
    "\n",
    "dann_embedding = dann_vis.predict([combined_test_imgs])\n",
    "dann_tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=300)\n",
    "tsne = dann_tsne.fit_transform(dann_embedding)\n",
    "\n",
    "plot_embedding(tsne, combined_test_labels.argmax(1),\n",
    "               combined_test_domain.argmax(1), 'DANN')\n",
    "\n",
    "#plt.show()\n",
    "# pltOut(os.path.join(run_name,\"tsne.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
